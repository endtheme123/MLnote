{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Milestone Project 1: Food Vision Big\n",
        "\n",
        "see the annotated version of this notebook on GitHub"
      ],
      "metadata": {
        "id": "5ygAm-JYFtCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==2.5.0\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "I_9K4hKEC15A",
        "outputId": "efed75df-445b-4c03-b852-e5def215806d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8fAE5PwRIhr",
        "outputId": "650fa768-71ab-44cc-84e8-982a1b400160"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.20.3\n",
            "  Using cached protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check our GPU\n",
        "\n",
        "* Google colab offers free GPUs (thank you Google), however, not all of them are compatible with mixed precision training.\n",
        "Google Colab offers:\n",
        "* K80 (Not compatible)\n",
        "* P100 (not compatible)\n",
        "* Tesla T4 (compatible)\n",
        "\n",
        "Knowing this, in order to use mixed precision training we need access to a Tesla T4 ( from within Google Colab) or if we're using our own hardware, our GPU needs a score of 7.0+ (see here: https://developer.nvidia.com/cuda-gpus#compute)"
      ],
      "metadata": {
        "id": "hGN_LEcyII2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#if the following line doesn't output \"Tesla T4\", you can try getting access to \n",
        "#another GPU by going to Runtime -> Factory Reset Runtime -> \"Yes\" and then\n",
        "#rerunning this cell\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErJknpJ6LNiQ",
        "outputId": "15065dac-5934-4a7f-b374-86d0c524a966"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-e672a513-07c7-d422-f71d-e78dda85c625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get helper functions\n",
        "\n",
        "In past modules, we've created a bunch of helper functions to do small tasks required for our notebooks.\n",
        "\n",
        "Rather than rewrite all of these, we can import a script and load them in from there.\n",
        "\n",
        "The script we've got available can be found on GitHub: https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "OeNYaE7eLP_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KhojK8IOAuR",
        "outputId": "728479a2-8204-431b-bdf0-f4434b1feaba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-26 06:34:41--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-26 06:34:41 (72.8 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import series of helper functions\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "shY6dC8-OFnj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use tensorflow dataset to download data\n",
        "\n",
        "If you want to get an overview of TensorFlow Dataset (TFDS), read the guide\n"
      ],
      "metadata": {
        "id": "q6vU5yoPOSal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get TensorFlow Dataset\n",
        "import tensorflow_datasets as tfds\n"
      ],
      "metadata": {
        "id": "pSrnd_v_PjIU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list all available datasets\n",
        "datasets_list = tfds.list_builders() #get all available datasets in TFDS\n",
        "\n",
        "print(\"food101\" in datasets_list) # is our target dataset in the list of TFDS datasets"
      ],
      "metadata": {
        "id": "YRD93gBdPsI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ef262d-04f3-435e-e9b7-3de0bbc3401f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data (takes 5-6 minutes in Google Colab)\n",
        "(train_data, test_data), ds_info = tfds.load(name = \"food101\",\n",
        "                                             split=[\"train\", \"validation\"],\n",
        "                                             shuffle_files = True,\n",
        "                                             as_supervised = True, #data returned in turple format (data, label)\n",
        "                                             with_info = True)"
      ],
      "metadata": {
        "id": "v8bs4YQEQF3_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "33b3b5a4-45fd-4625-9fd1-d3d56b667ff1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-421ab882daa4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load in the data (takes 5-6 minutes in Google Colab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m (train_data, test_data), ds_info = tfds.load(name = \"food101\",\n\u001b[0m\u001b[1;32m      3\u001b[0m                                              \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                              \u001b[0mshuffle_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                              \u001b[0mas_supervised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#data returned in turple format (data, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/logging/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    627\u001b[0m   \u001b[0mas_dataset_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'read_config'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m   \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mas_dataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/logging/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mas_supervised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_supervised\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     )\n\u001b[0;32m--> 781\u001b[0;31m     \u001b[0mall_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_single_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 435\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 435\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_build_single_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0;31m# Build base dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m     ds = self._as_dataset(\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0mshuffle_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_as_dataset\u001b[0;34m(self, split, decoders, read_config, shuffle_files)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     )\n\u001b[1;32m   1251\u001b[0m     \u001b[0mdecode_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     return reader.read(\n\u001b[0m\u001b[1;32m   1253\u001b[0m         \u001b[0minstructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0msplit_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, instructions, split_infos, read_config, shuffle_files, disable_shuffling, decode_fn)\u001b[0m\n\u001b[1;32m    411\u001b[0m       )\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_read_instruction_to_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m   def read_files(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 435\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 435\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/reader.py\u001b[0m in \u001b[0;36m_read_instruction_to_ds\u001b[0;34m(instruction)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_instruction_to_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m       \u001b[0mfile_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplits_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_instructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m       return self.read_files(\n\u001b[0m\u001b[1;32m    406\u001b[0m           \u001b[0mfile_instructions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m           \u001b[0mread_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/reader.py\u001b[0m in \u001b[0;36mread_files\u001b[0;34m(self, file_instructions, read_config, shuffle_files, disable_shuffling, decode_fn)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;31m# Read serialized example (eventually with `tfds_id`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     ds = _read_files(\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0mfile_instructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_instructions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mread_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_datasets/core/reader.py\u001b[0m in \u001b[0;36m_read_files\u001b[0;34m(file_instructions, read_config, shuffle_files, disable_shuffling, file_format)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mdeterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   ds = instruction_ds.interleave(\n\u001b[0m\u001b[1;32m    287\u001b[0m       functools.partial(\n\u001b[1;32m    288\u001b[0m           \u001b[0m_get_dataset_from_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36minterleave\u001b[0;34m(self, map_func, cycle_length, block_length, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2425\u001b[0m       \u001b[0mshift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2426\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mWindowDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2427\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2428\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2429\u001b[0m     \"\"\"Reduces the input dataset to a single element.\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'interleave_op' from 'tensorflow.python.data.ops' (/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Food101 data from TensorFlow Dataset\n",
        "To become one with our data, we want to find:\n",
        "* Class names\n",
        "* The shape of our input data (image tensors)\n",
        "* The datatype of our input data\n",
        "* What the labels look like (e.g. are they one-hot encoded or are they label encoded?)\n",
        "* Do the label match up with the calss names?"
      ],
      "metadata": {
        "id": "wz9J0WcUXmOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Features of Food101 from TFDS\n",
        "ds_info.features"
      ],
      "metadata": {
        "id": "86VgLNEjRP5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "194e5ad9-268d-49e5-ad3c-2b5e692959fe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-fdf401a1f208>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Features of Food101 from TFDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ds_info' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the class names\n",
        "class_names = ds_info.features[\"label\"].names\n",
        "class_names[:10]"
      ],
      "metadata": {
        "id": "C96k5CW3XMKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Take one sample of the train data\n",
        "train_one_sample = train_data.take(1) # sample are in format (image_tensor, label)"
      ],
      "metadata": {
        "id": "0HkDzLifYPiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what does one sample of our training data look like\n",
        "train_one_sample"
      ],
      "metadata": {
        "id": "jlGz1w3jYgWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output info about our training sample\n",
        "for image, label in train_one_sample:\n",
        "  print(f\"\"\"\n",
        "  Image shape: {image.shape},\n",
        "  Image datatype: {image.dtype},\n",
        "  Target class from Food101 (tensor form): {label},\n",
        "  Class name (str form): {class_names[label.numpy()]}\n",
        "  \n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "lFscW-t1Y4Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What does our image tensor from TFDS's Food101 look like?\n",
        "image"
      ],
      "metadata": {
        "id": "5VRgGe3DZq4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "#what are the min and max values of our image tensor\n",
        "tf.reduce_min(image), tf.reduce_max(image)"
      ],
      "metadata": {
        "id": "kDRke2oYaNBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot an image from tensorFlow Datasets\n"
      ],
      "metadata": {
        "id": "97WHyGPIajT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_info"
      ],
      "metadata": {
        "id": "DRMDcHpZcalO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#Plot an image tensor\n",
        "target_data = train_data.take(1)\n",
        "plt.figure()\n",
        "for image, label in target_data:\n",
        "  plt.imshow(image)\n",
        "  plt.title(f\"label:{class_names[label.numpy()]}\") #add title to image to verify the label is associate with the right image\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "AKGmvKOpcCFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create preprocessing functions for our data\n",
        "\n",
        "Neural networks perform best when data is in a certain way (e.g. batched, normalized, etc)\n",
        "\n",
        "However, not all data (including data from TensorFlow Datasets) comes like this\n",
        "\n",
        "So in order to get it ready for a neural network, you 'll often have to write preprocessing functions and map it to your data.\n",
        "\n",
        "What we know about our data:\n",
        "* In `uint8` datatype\n",
        "* Comprised of all different size tensors (different sized images)\n",
        "* Not scaled (the pixel values are between 0 and 255)\n",
        "\n",
        "What we know models like:\n",
        "* Data in `float32` dtype (or for mixed precision `fload16` and `float32`)\n",
        "* For batches, TensorFlow likes all of the tensors within a batch to be the same size\n",
        "* Scaled (values between 0 & 1) also called normalized tensors generally perform better\n",
        "\n",
        "With these points in mind, we've got a few things we can tackle with a preprocessing function.\n",
        "\n",
        "Since we're going to be using an EfficientNetBX pretrained model from tf.keras.applications, we don't need to rescale our data (these architecture have rescaling built-in)\n",
        "\n",
        "This means our functions need to:\n",
        "1. Reshape our images to all the same size\n",
        "2. Convert the dtype of our image tensors from `uint8` to `float32`"
      ],
      "metadata": {
        "id": "xh9poubrd_--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make a function for preprocessing images\n",
        "def preprocess_img(image, label, image_shape = 224):\n",
        "  \"\"\"\n",
        "  Converts image data type from 'uint8' -> 'float32'\n",
        "  Reshapes image to (image_shape, image_shape, color_channels)\n",
        "  \"\"\"\n",
        "  image = tf.image.resize(image, [image_shape, image_shape]) #reshape target image\n",
        "  # image = image/255. #scale image values => not required with EfficientNetBX model from tf.keras.applications\n",
        "  return tf.cast(image, dtype = tf.float32), label # return (float32_image, label) tuple\n"
      ],
      "metadata": {
        "id": "dom5lFJDg7D5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess a single sample image and check the outputs\n",
        "preprocessed_image = preprocess_img(image, label)[0]\n",
        "print(f\"image before preprocessing:\\n {image[:2]}...., \\nShape: {image.shape}, \\nDatatype: {image.dtype}\\n\")\n",
        "print(f\"image after preprocessing:\\n {preprocessed_image[:2]},...., \\nShape: {preprocessed_image.shape}, \\nDatatype: {preprocessed_image.dtype}\\n\" )"
      ],
      "metadata": {
        "id": "50Mw3KFBja2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Batch and prepare datasets\n",
        "\n",
        "We're now going to make our data input pipeline run really fast.\n",
        "\n",
        "For more resources on this, I'd highly going through the following guide: https://www.tensorflow.org/guide/data_performance\n"
      ],
      "metadata": {
        "id": "o4vrHLv0kaQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#map preprocessing function to training (and parallelize)\n",
        "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "\n",
        "#Shuffle train_data and turn it into batches and prefetch it (load it faster)\n",
        "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size = 32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "#map preprocessing function to test data\n",
        "test_data = test_data.map(map_func = preprocess_img, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "83sZcD3dmkOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "xD30e3-4qRbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> \"Hey, Tensorflow, map this preprocessing function(`preprocess_img`) accross our training dataset, then shuffle a number of elements and then batch them together and finally make sure you prepare new batches (prefetch) whilst the model is looking through (finding patterns) the current batch\""
      ],
      "metadata": {
        "id": "GZQYdID9qb8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create modelling callback\n",
        "\n",
        "We're going to create a couple of callbacls to help us while our model trains:\n",
        "* TensorBoard callback to log training results ( so we can visualize them later if need to be)\n",
        "* ModelCheckpoint callback to save our model's progress after feature extraction"
      ],
      "metadata": {
        "id": "jNK04VUzvdV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback (inport from helper_function.py)\n",
        "\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "#create a model checkpoint callback to save our model's progress during training\n",
        "checkpoint_path = \"model_checkpoints/cp.ckpt\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      monitor = \"val_acc\",\n",
        "                                                      save_best_only = True,\n",
        "                                                      save_weights_only=True,\n",
        "                                                      verbose = 0)# don't print whether or not model is being saved"
      ],
      "metadata": {
        "id": "b4hmWHsgxfgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup mixed precision training\n",
        "\n",
        "First and foremost, for a deeper understanding of mixed precision training, check out the TensorFlow guide for mixed precision: https://www.tensorflow.org/guide/mixed_precision\n",
        "\n",
        "Mixed precision utilizes a combination of float32 and float16  data types to speed up model performance"
      ],
      "metadata": {
        "id": "0CRboZuVycl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn on mixed precision training\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\") #set global data policy to mixed precision"
      ],
      "metadata": {
        "id": "ICOwRPHc0GcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision.global_policy()"
      ],
      "metadata": {
        "id": "ZZ7egrsN0xk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build feature extraction model \n"
      ],
      "metadata": {
        "id": "KUYd5cR61c3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Create base model\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "base_model =tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create functional model\n",
        "inputs = layers.Input(shape = input_shape, name=\"input_layer\")\n",
        "#note: efficientnetBX models have rescaling built-in but if your model doesn't you can have a layer like below\n",
        "#x = preprocessing.Rescaling(1./255)(inputs)\n",
        "\n",
        "x = base_model(inputs, training = False) # make sure layers which should be in inference must only stay the same\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(len(class_names))(x)\n",
        "outputs = layers.Activation(\"softmax\", dtype = tf.float32, name = \"softmax_float32\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "#compile our model\n",
        "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics = [\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "Vb1zOvqU5G0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "miTghzx87YQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking layer dtype policies (are we using mixed precision?)\n"
      ],
      "metadata": {
        "id": "vfDv2FtM7ZnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the dtype_policy attributes of layers in our model\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "metadata": {
        "id": "RpuwTB_m7yUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Going through the above we see:\n",
        "* `layer.name`: the human readable name of a particular layer\n",
        "* `layer.trainable` : is the layer trainable or not (if `False`, the weights are frozen)\n",
        "* `layer.dtype`: the data type a layer stores its variables in \n",
        "* `layer.dtype_policy`: the data type policy a layer computes on its variables with  "
      ],
      "metadata": {
        "id": "yFDbYmxJ8VXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dtype_policy attributes of layers in base model\n",
        "for layer in model.layers[1].layers[:20]: #check the layers of the base model(layer at the index 1 of model)\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "metadata": {
        "id": "WYuUygMc87Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fit the feature extraction model\n",
        "\n",
        "if our goal is to fine-tune a pretrained model, the general order of doing thing is:\n",
        "  1. build a feature extraction model (train a couple output layers with base layers frozen)\n",
        "  2. Fine-tune some of the frozen layers"
      ],
      "metadata": {
        "id": "HJInhgpJ_OtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model\n",
        "model_101_food_classes_feature_extract = model.fit(train_data,\n",
        "                                                   epochs = 3,\n",
        "                                                   steps_per_epoch = len(train_data),\n",
        "                                                   validation_data = test_data,\n",
        "                                                   validation_steps = int(0.15*len(test_data)),\n",
        "                                                   callbacks = [create_tensorboard_callback(\"training_logs\", \"efficientnetb0_101_classes_all_data_feature_extract\"), \n",
        "                                                                model_checkpoint])"
      ],
      "metadata": {
        "id": "YG0uYWc69SlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate model on whole test dataset\n",
        "results_feature_extract_model = model.evaluate(test_data)\n",
        "results_feature_extract_model"
      ],
      "metadata": {
        "id": "MiHO8yvrAmDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Off to you...\n",
        "\n",
        "We've covered alot of ground so far but since this is a milestone project, it's time for you to takeover.\n",
        "\n",
        "More specifically, you're challenge is to complete the TEMPLATE version of 07 to obtain a computer vision model (building off the one we've built in this notebook) to beat the DeepFood paper (77,4%)\n",
        "\n",
        "In other words, you're going to create food vision big"
      ],
      "metadata": {
        "id": "wmev_T4MF5Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPiWjYU8GYWt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}