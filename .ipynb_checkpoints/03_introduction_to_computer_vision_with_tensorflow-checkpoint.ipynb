{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5j2N7b_YSk1R"
   },
   "source": [
    "**What is a computer vision problem?**\n",
    "* Binary classification problem\n",
    "* Multi-class classification\n",
    "* Object detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTehNnQOTTgu"
   },
   "source": [
    "#Introduction to convolutional neural networks and computer vision with tensorflow\n",
    "\n",
    "Computer vision is the practice of writing\n",
    "algorithms which can discover patterns in visual data. Such as the camera of a self-driving car recognize the car in front."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ubMvyLPXxe6"
   },
   "source": [
    "## Get the data \n",
    "\n",
    "the images we're working with are from the food101 dataset (101 different classes of food): https://www.kaggle.com/datasets/dansbecker/food-101\n",
    "\n",
    "However we've modified it to only use 2 classses (pizza and steak) using the image data modification notebook (check danial's github)\n",
    "\n",
    ">**Note:** we start with a smaller dataset so we can experiment quickly and figure what works (or better yet what doesn't work) before scaling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BmqKK9XFYFEy",
    "outputId": "38beb090-6c20-49f1-cc73-77376154dd11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pizza_steak.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15092\\688014034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#unzip downloaded file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mzip_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pizza_steak.zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[0;32m   1238\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pizza_steak.zip'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "#download to gg colab\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
    "\n",
    "#unzip downloaded file\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"pizza_steak.zip\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1ekh5elZGIN"
   },
   "source": [
    "## Inspect the data (become one with it)\n",
    "\n",
    "A very crucial step at the beginning of any machine learning project is becoming one with the data.\n",
    "\n",
    "And for a computer vision project, this usually means visualizing many samples of your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hQA20m4ai3K",
    "outputId": "11b5b945-2bf7-4712-edd7-2bc8baf13bdc"
   },
   "outputs": [],
   "source": [
    "!ls pizza_steak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7J1qIR5ak6g",
    "outputId": "538f4b09-e132-443c-eb22-c860915cfaf4"
   },
   "outputs": [],
   "source": [
    "!ls pizza_steak/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPCipP2Aaq-E",
    "outputId": "40669e67-3f24-4dd2-f18c-d6edb21ebbd1"
   },
   "outputs": [],
   "source": [
    "!ls pizza_steak/train/steak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFDPExNuaubF",
    "outputId": "067dec39-4b4a-40d0-a68b-1e4bf2048fa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#walkthrough the pizza_steak directory and list number of files\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n",
    "  print(f\"there are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQSYK6pUbLtA",
    "outputId": "158a789b-7326-4171-9acf-7d1bfbde3150"
   },
   "outputs": [],
   "source": [
    "# Another way to find out how many images in a file\n",
    "\n",
    "num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n",
    "\n",
    "num_steak_images_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kdLfPOIb615"
   },
   "source": [
    "To visualize our images, first let's get the class names programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_F3xAXfb3bz",
    "outputId": "e0b79c46-c3f9-45dc-e7bd-86a80bf0784d"
   },
   "outputs": [],
   "source": [
    "#get the classnames programmatically\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "data_dir = pathlib.Path(\"pizza_steak/train\")\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # Created a list of class_names from the sub directories \n",
    "# if ds_store appear then we will need to remove it\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1VCbqE5cn0X"
   },
   "outputs": [],
   "source": [
    "#let's visualize our images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "import random\n",
    "\n",
    "def view_random_image(target_dir, target_class):\n",
    "  #setup the target directory (we'll view images from here)\n",
    "  target_folder = target_dir +\"/\"+ target_class\n",
    "\n",
    "  #get a random image path\n",
    "  random_image = random.sample(os.listdir(target_folder),1)\n",
    "  print(random_image)\n",
    "  #read in the image and plot it using matplotlib\n",
    "\n",
    "  img = mping.imread(target_folder + \"/\" + random_image[0])\n",
    "  plt.imshow(img)\n",
    "  plt.title(target_class)\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  print(f\"image shape: {img.shape}\") #show the shape of the image\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "Jqm-vhneeD_5",
    "outputId": "c294d0b0-545e-45da-add7-252f5bb5204e"
   },
   "outputs": [],
   "source": [
    "#view random image from the training dataset\n",
    "img = view_random_image(target_dir = \"pizza_steak/train\",\n",
    "                        target_class = \"pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRFBbik3eV0m",
    "outputId": "b5b03685-c5a7-4dbc-b1fa-10928547f12a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.constant(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wLD4k5Mfhww",
    "outputId": "767fd450-e9e2-4e6c-9c75-4cba0fb61865"
   },
   "outputs": [],
   "source": [
    "#view the image shape\n",
    "img.shape # return width, height, colour channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x09SU2FcgElG",
    "outputId": "c8ccea7a-144b-4b3d-c5a8-9b0cc658f3eb"
   },
   "outputs": [],
   "source": [
    "#get all the pixel values between 0 and 1\n",
    "img/225."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjY_OrbqgcZ1"
   },
   "source": [
    "## an end-to-end example\n",
    "\n",
    "let's build a convolutional neural network to find patterns in our images, more specifically we need a way to:\n",
    "* load our images\n",
    "* preprocess images\n",
    "* build a CNN to find patterns in our images\n",
    "* compile our CNN\n",
    "*fit our CNN to our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Na-NnNLa7Xjw",
    "outputId": "85b89d51-0c89-4b28-d3fe-c6e18d165fd9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#preprocess data (get all of the pixel values between 0 and 1, also called scaling/normalization)\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#set up paths to our data directories\n",
    "train_dir = \"pizza_steak/train\"\n",
    "test_dir = \"pizza_steak/test\"\n",
    "\n",
    "#import data from directories and turn it into batches\n",
    "train_data = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                               batch_size=32,\n",
    "                                               target_size = (224,224),\n",
    "                                               class_mode = \"binary\",\n",
    "                                               seed=42)\n",
    "test_data = valid_datagen.flow_from_directory(directory = test_dir,\n",
    "                                              batch_size = 32,\n",
    "                                              target_size = (224,224),\n",
    "                                              class_mode = \"binary\",\n",
    "                                              seed = 42)\n",
    "\n",
    "print(test_data)\n",
    "#Build a CNN model(same as tiny VGG on the CNN explainer website)\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters = 10,\n",
    "                           kernel_size = 3,\n",
    "                           activation = \"relu\",\n",
    "                           input_shape=(224,224,3)),\n",
    "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2,\n",
    "                             padding =\"valid\"),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation = \"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "#Compile our function\n",
    "\n",
    "model_1.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "#fit the model\n",
    "history_1 = model_1.fit(train_data,\n",
    "                        epochs = 5,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps = len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygOUy9xLZ3cu"
   },
   "source": [
    ">**note:** if the above cell is taking longer than 10s seconds per epoch, make sure you're using a GPU by going to Runtime -> Change runtime type -> Hardware accelerator -> GPU (you may have to return some cells above after doing this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWbP14zSEWsr",
    "outputId": "350e3067-f873-4e45-889f-37aa0fc6fb6b"
   },
   "outputs": [],
   "source": [
    "#Get a model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW040UOia8nG"
   },
   "source": [
    "## using the same model as before\n",
    "\n",
    "let's replication the model we've built in the previous section to see if it works with our image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ky0jumAkiEFY",
    "outputId": "1f562f5a-9351-472f-aa5e-be2be0ae981b"
   },
   "outputs": [],
   "source": [
    "#set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Create a model to replication the tensorflow playground model\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(224,224,3)),\n",
    "    tf.keras.layers.Dense(4, activation =\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "\n",
    "#compile the model\n",
    "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "#fit the model\n",
    "history_2 = model_2.fit(train_data,\n",
    "                        epochs = 5,\n",
    "                        steps_per_epoch = len(train_data),\n",
    "                        validation_data = test_data,\n",
    "                        validation_steps = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emaXUxLUj6Be",
    "outputId": "859430fa-bf93-457c-c586-48415d4bfe59"
   },
   "outputs": [],
   "source": [
    "#get a summary of model_2\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KCGk8j8mTpy"
   },
   "source": [
    "Despite having 20x more parameters than our CNN (model_1), model_2 performs terribly... Let's try to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaUMRc8GjEg6",
    "outputId": "d712109f-3fa5-43a5-a3fb-af65c25de675"
   },
   "outputs": [],
   "source": [
    "#update the model above\n",
    "\n",
    "#set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#create the model\n",
    "model_3=tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(224,224,3)),\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "\n",
    "#compile the model\n",
    "model_3.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer = tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "#fit the model\n",
    "model_3.fit(train_data,\n",
    "            epochs = 5,\n",
    "            steps_per_epoch = len(train_data),\n",
    "            validation_data = test_data,\n",
    "            validation_steps = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ruZTTCwAniYw",
    "outputId": "8b297dce-0d92-4818-c7e0-bed06448c643"
   },
   "outputs": [],
   "source": [
    "#get a summary of model_3\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtOLx3lUogkt"
   },
   "source": [
    "**note:** you can think of trainable parameters as **patterns a model can learn from data**. Intuitively, you might think more is better. And in lots of cases, it is. But in this case, the difference here is the 2 different styles of model we're using. Where a series of dense layers has a number of different learnable parameters connected to each other and hence a higher number of possible learnable patterns, **a convolutional seeks to sort our and learn the most important patterns in an image** so even through these are less learnable parameters in our convolutional neural network, these are often more helpful in deciphering between **features** in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOv74ETBreiZ"
   },
   "source": [
    "## Binary classification: let's break it down\n",
    "\n",
    "1. become 1 with the data (visualize, visualize, visualize)\n",
    "2. preprocess the data (prepared it for our model, the main step here was scaling/ normalizing and turing our data into batches)\n",
    "3. Create a model (start with a baseline)\n",
    "4. Fit the model\n",
    "5. Evaluate the model\n",
    "6. Adjust different parameters and improve the model (try to beat our baseline)\n",
    "7. Repear until satisfied (experiment, experiment, experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bXB7Mvjs42f"
   },
   "source": [
    "### 1. become one with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "2bp4yTZMs_Ji",
    "outputId": "efe7e74a-288b-4d4f-c21c-6f32fd24b8d4"
   },
   "outputs": [],
   "source": [
    "#visualize the data\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "steak_img = view_random_image(\"pizza_steak/train\", \"steak\")\n",
    "plt.subplot(1,2,2)\n",
    "pizza_img = view_random_image(\"pizza_steak/train\", \"pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcrGcRzotb-v"
   },
   "source": [
    "### 2. preprocess the data (prepare it for the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RBtAu0Mui7g"
   },
   "outputs": [],
   "source": [
    "#Define directory data paths\n",
    "train_dir = \"pizza_steak/train/\"\n",
    "test_dir = \"pizza_steak/test/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSKs-lV_uxXn"
   },
   "source": [
    "Next step is to turn our data into **batches**.\n",
    "\n",
    "\n",
    "a batch is a small subset of our data. rather than look at all the data at one time, a model might only look at 32 at a time.\n",
    "\n",
    "It does this for a couple of reasons:\n",
    "1. 10,000 images or more might not fit into the memory of your processor (GPU)\n",
    "2. Trying to learn the patterns in 10,000 in 1 hit could result in the model not being able to learn very well.\n",
    "\n",
    "Why 32?\n",
    "\n",
    "because 32 is good for your health..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTL5jsf4u2nc"
   },
   "outputs": [],
   "source": [
    "# Create train and test data generator and rescale the data\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DUpStpqy5RM",
    "outputId": "438d9671-bb1f-4409-bafb-31abcc5a5faf"
   },
   "outputs": [],
   "source": [
    "\n",
    "#path to our data\n",
    "train_dir = \"pizza_steak/train\"\n",
    "test_dir = \"pizza_steak/test\"\n",
    "\n",
    "#generate the data\n",
    "train_data = train_datagen.flow_from_directory(directory = train_dir, #target directory of image\n",
    "                                               target_size = (224,224), #target size of image (height, width)\n",
    "                                               class_mode = \"binary\", #type of data you're working with\n",
    "                                               batch_size = 32, # size of mini batches to load data into\n",
    "                                               seed = 42\n",
    "                                               )\n",
    "test_data = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                             target_size = (224,224),\n",
    "                                             class_mode = \"binary\",\n",
    "                                             batch_size = 32,\n",
    "                                             seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIXnPp7jvP0l",
    "outputId": "2ce4c815-05eb-4309-8994-5a2139eb71a7"
   },
   "outputs": [],
   "source": [
    "#get a sample of a training data batch\n",
    "images, labels = train_data.next() # get the \"next\" batch of images/ label in the train data\n",
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wb8t0g8n07ln",
    "outputId": "6a0c12c6-5fb7-40dd-a4a6-253b5cba54c5"
   },
   "outputs": [],
   "source": [
    "#how many batches are there\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5F_g-xap1Bmr",
    "outputId": "b0717ed5-7e3a-4108-f084-28747c8fb650"
   },
   "outputs": [],
   "source": [
    "# get the first 2 images\n",
    "images[:2], images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KW8at9Km1L52",
    "outputId": "4f3163c2-dde9-44d3-bd2c-b13517ca1fe3"
   },
   "outputs": [],
   "source": [
    "images[7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfnSxFPu1j8M",
    "outputId": "b031036b-7398-40a0-a15d-62277c5a605c"
   },
   "outputs": [],
   "source": [
    "# view the first batch of labels\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jY1GjHrd1v0T"
   },
   "source": [
    "###3. Create a CNN model (start with a baseline)\n",
    "\n",
    "A baseline is a relatively simple model or existing result that you setup when begining a machine learning experiment and then as you keep experimenting, you try to beat the baseline\n",
    "\n",
    "> **Note:** In deep learning, there is almost infinite amount of architectures you could create. So one of the beset ways to get started is to start with something  simple and see if it works on your data and then introduce complexity as required (e.g. look at which current model is performing best in the file of your problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSyvmlIN21Sp"
   },
   "outputs": [],
   "source": [
    "#make the creating of our model a little easier\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dynmkah13alG"
   },
   "outputs": [],
   "source": [
    "#create the model\n",
    "model_4 = Sequential([\n",
    "    Conv2D(filters = 10, #filter is the number of sliding windows going across the imput => higher => more complex\n",
    "           kernel_size = (3,3), #the size of the sliding window goes across an input\n",
    "           strides =(1,1), # the size of the step sliding window takes across an input\n",
    "           padding = \"valid\", # if same => output shape is same as input shape, if valid => output shape gets compressed\n",
    "           activation = \"relu\",\n",
    "           input_shape = (224,224,3)), #input layer ( specifiy input shape)\n",
    "    Conv2D(10,3,activation = \"relu\"),\n",
    "    Conv2D(10,3, activation = \"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(1 , activation = \"sigmoid\") # output layer (working with binary classification so only 1 output neuron)\n",
    "\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivxAsDwpCojB"
   },
   "source": [
    "### 3. comile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrZ9e2RJCDC2"
   },
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model_4.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2mmpmQTCQxb",
    "outputId": "7e8c842c-1941-441b-89d3-144bb1761cce"
   },
   "outputs": [],
   "source": [
    "#get a summary of our model\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sY0cJwYCUN-"
   },
   "source": [
    "###4. fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsEaAmYvCskA",
    "outputId": "1c969eee-a687-4740-b6a2-eda77843cb37"
   },
   "outputs": [],
   "source": [
    "#check length of training and testing data generator\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLl0aGWvDC1o",
    "outputId": "a75a18e5-9921-479f-f816-fff19fc4ab5c"
   },
   "outputs": [],
   "source": [
    "#fit the model\n",
    "history_4 = model_4.fit(train_data, #this is a combination of labels and sample data\n",
    "                        epochs = 5,\n",
    "                        steps_per_epoch = len(train_data),\n",
    "                        validation_data = test_data,\n",
    "                        validation_steps = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ej5JTtARDe-r",
    "outputId": "1dff1019-45dd-44f9-a6c3-8513627e0ada"
   },
   "outputs": [],
   "source": [
    "model_1.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIwAeC5xD8y6",
    "outputId": "529cb0d4-29a4-4da9-b200-f4b01b8422d7"
   },
   "outputs": [],
   "source": [
    "model_4.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OqmWGhCEIoS"
   },
   "source": [
    "### 5. Evaluating our model\n",
    "\n",
    "it looks like our model is learning something, let's evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "HoGVbdcWFUn1",
    "outputId": "9d508a1a-3c9d-42ce-d6cf-f43c44ded287"
   },
   "outputs": [],
   "source": [
    "#let's plot the loss curves\n",
    "import pandas as pd\n",
    "pd.DataFrame(history_4.history).plot(figsize = (10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riTFK9OwFt2z"
   },
   "outputs": [],
   "source": [
    "#plot the validation and training curves separately\n",
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  returns separate loss curves for training and validation metrics\n",
    "  \"\"\"\n",
    "  \n",
    "  loss = history.history[\"loss\"]\n",
    "  val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "  accuracy = history.history[\"accuracy\"]\n",
    "  val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "  epochs = range(len(history.history[\"loss\"])) #how many epochs did we run for\n",
    "\n",
    "  #plot loss\n",
    "  plt.plot(epochs, loss, label=\"training_loss\")\n",
    "  plt.plot(epochs, val_loss, label=\"val_loss\")\n",
    "  plt.title(\"loss\")\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.legend()\n",
    "\n",
    "\n",
    "  plt.figure()\n",
    "  #plot accuracy\n",
    "  plt.plot(epochs, accuracy, label=\"training_accuracy\")\n",
    "  plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n",
    "  plt.title(\"accuracy\")\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAA8ehoRKRkT"
   },
   "source": [
    "> **Note:** when a model's **validation loss starts to increase**, it's likely that the model is **overfitting** the training dataset. This means, it's learning the patterns in the training dataset *too well* and thus the model's ability to generalize to unseen data will be diminished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "kIrE9eI7JB3S",
    "outputId": "414fef9b-9f82-4292-c822-6107765ba10d"
   },
   "outputs": [],
   "source": [
    "#check out the loss and accuracy\n",
    "plot_loss_curves(history_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5B_ljJJKB2V"
   },
   "source": [
    "###6. adjust the model parameters\n",
    "\n",
    "Fitting a machine learning model com in 3 steps:\n",
    "\n",
    "0. create a baseline\n",
    "1. Beat the baseline by overfitting a larger model\n",
    "2. Reduce overfitting\n",
    "\n",
    "\n",
    "ways to induce overfitting:\n",
    "* increase the number of conv layers\n",
    "* increate the number of conv filters\n",
    "* add another dense layer to the output of our flattened layer\n",
    "\n",
    "Reduce overfitting:\n",
    "* add data augmentation\n",
    "* add regularization layers (such as MaxPool2D\n",
    "* Add more data...\n",
    "\n",
    ">**note:** reducing overfitting is also known as **regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xx90jLkVMZ8a"
   },
   "outputs": [],
   "source": [
    "#Create the model (this is going to be our new baseline)\n",
    "\n",
    "model_5 = Sequential([\n",
    "    Conv2D(10,3,activation = \"relu\", input_shape=(224,224,3)),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(10,3,activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10,3,activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKemH17pNLCP",
    "outputId": "75f9b93a-6435-479b-c10e-4f245556e5d3"
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer = Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history_5 = model_5.fit(train_data,\n",
    "                        epochs = 5,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data = test_data,\n",
    "                        validation_steps = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4yFFU3LOGOv",
    "outputId": "05c2d0b0-fe0a-4a2a-ad64-f86f893ace0b"
   },
   "outputs": [],
   "source": [
    "#get a summary of or model with max pooling\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "_8UN5RkqOjrG",
    "outputId": "586cca26-2c35-4290-aa34-89ff20ba3acb"
   },
   "outputs": [],
   "source": [
    "#plot loss curves\n",
    "plot_loss_curves(history_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wauoeBOvO45v"
   },
   "source": [
    "### opening our bag of tricks and finding data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjhC9dLsQqHu"
   },
   "outputs": [],
   "source": [
    "#Create ImageDataGenerator training instance with data augmentation\n",
    "\n",
    "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
    "                                             rotation_range=0.2, #how much do you want to rotate an image\n",
    "                                             shear_range=0.2, # how much do you want to shear an image\n",
    "                                             zoom_range=0.2, #zoom in randomly an image\n",
    "                                             width_shift_range=0.2, #move random in x-axis\n",
    "                                             height_shift_range = 0.2, #move random in y-axis\n",
    "                                             horizontal_flip=True) #do you want to flip an image\n",
    "#Create ImageDataGenerator without data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
    "\n",
    "#create ImageDataGenerator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOXhVO3rSELA"
   },
   "source": [
    ">**Question:** what is data augmentation?\n",
    "\n",
    "Data augmentation is the process of altering our training data, leading it to have more diversity and in turn allowing our models to learn more generalizable (hopefully) patterns. Altering might means adjusting the rotation of an image, flipping it or cropping it....\n",
    "\n",
    "Let's write some code to visulaize data augmentation.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYNB9_tOWX4D",
    "outputId": "ec60dc0c-20bc-4405-8012-a032e717f0c9"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)\n",
    "\n",
    "\n",
    "#import data and augment it from training directory\n",
    "print(\"augmented training data\")\n",
    "\n",
    "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
    "                                                                   target_size= IMG_SIZE,\n",
    "                                                                   batch_size = 32,\n",
    "                                                                   class_mode=\"binary\",\n",
    "                                                                   shuffle=False) #for demonstation purposes only\n",
    "\n",
    "#create non-augmented train data batches\n",
    "print(\"non-augmented train data\")\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size=IMG_SIZE,\n",
    "                                               batch_size=32,\n",
    "                                               class_mode=\"binary\",\n",
    "                                               shuffle=False)\n",
    "\n",
    "#create non-augmented test data batches\n",
    "print(\"non-augmented test data\")\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size=IMG_SIZE,\n",
    "                                             batch_size=32,\n",
    "                                             class_mode=\"binary\"\n",
    "                                             )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hi50cQy6YbYO"
   },
   "source": [
    "**Note:** Data augmentation is usually only performed on the training data. Using `ImageDataGenerator` built-in data augmentation parameters our image are left as they are in the directories but are modified as they're lo.aded into the model\n",
    "\n",
    "\n",
    "Finally... let's visualize some augmented data!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-d2pq5WYMvv"
   },
   "outputs": [],
   "source": [
    "#Get sample augmented data batches\n",
    "images, labels = train_data.next()\n",
    "augmented_images, augmented_labels = train_data_augmented.next() #note: labels aren't augmented... only data images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "i46vRkheZaz4",
    "outputId": "cd3ed4df-6d01-48d9-aa30-2a4acb42da8a"
   },
   "outputs": [],
   "source": [
    "#show the original images and augmented image\n",
    "import random\n",
    "random_number = random.randint(0,32) # our batch sizes are 32\n",
    "print(f\"showing image number:{random_number}\")\n",
    "plt.imshow(images[random_number])\n",
    "\n",
    "plt.title(f\"original image\")\n",
    "plt.axis(False)\n",
    "plt.figure()\n",
    "\n",
    "plt.imshow(augmented_images[random_number])\n",
    "plt.title(f\"augmented image\")\n",
    "plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adYI3YsUdKHR"
   },
   "source": [
    "Now we've seen what augmented training data looks like, let's build a model and see how it learns on augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mA7OKi9laB2T",
    "outputId": "d149fece-99a4-4cf0-c327-2473692ec8cf"
   },
   "outputs": [],
   "source": [
    "# Create a model (same as model 5)\n",
    "\n",
    "model_6 = Sequential ([\n",
    "    Conv2D(10,3,activation = \"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(10,3,activation = \"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10,3,activation = \"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "#Compile the model\n",
    "model_6.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "#Fit the model\n",
    "history_6=model_6.fit(train_data_augmented, #fitting model_6 on augmented trainind data\n",
    "                      epochs = 5,\n",
    "                      steps_per_epoch = len(train_data_augmented),\n",
    "                      validation_data = test_data,\n",
    "                      validation_steps = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "uT1NhSTWfUAf",
    "outputId": "f555e2bc-8f3b-44bc-e53b-13b7c405ef0d"
   },
   "outputs": [],
   "source": [
    "#Check our model training curves\n",
    "plot_loss_curves(history_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BTIFBDNkf-e"
   },
   "source": [
    "Let's shuffle our augmented training data and train another model (the same as before) on it and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvhGjdqJgMBl",
    "outputId": "c439c18e-7407-4ffa-8529-624f8ff2c9d7"
   },
   "outputs": [],
   "source": [
    "#reimport data and augmented it and shuffle from training directory\n",
    "train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n",
    "                                                                            target_size = IMG_SIZE,\n",
    "                                                                            batch_size = 32,\n",
    "                                                                            class_mode = \"binary\",\n",
    "                                                                            seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1VORpmVi0Xw",
    "outputId": "9057c7d5-b33f-48cf-acaf-63479c2766e1"
   },
   "outputs": [],
   "source": [
    "#set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Create a model\n",
    "model_7 = Sequential([\n",
    "    Conv2D(10,3,activation=\"relu\",input_shape = (224,224,3)),\n",
    "    MaxPool2D(pool_size = 2),\n",
    "    Conv2D(10,3,activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10,3,activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "model_7.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer = tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "#fit the model\n",
    "history_7 = model_7.fit(train_data_augmented_shuffled, #we're fitting on augmented data and shuffle\n",
    "            epochs= 5,\n",
    "            steps_per_epoch=len(train_data_augmented_shuffled),\n",
    "            validation_data = test_data,\n",
    "            validation_steps = len(test_data)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3e3RTUi6m8A",
    "outputId": "c9ec495d-8229-4128-a78a-ddbb5cad03a0"
   },
   "outputs": [],
   "source": [
    "#summary of model 7\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "EI_EgfRZkGkG",
    "outputId": "9f8e18d4-d304-466e-96fa-77a52fd09cc4"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUjHEkGSmBuT"
   },
   "source": [
    "### 7. repeat until satisfied\n",
    "\n",
    "Since we've already beaten our baseline, there're only a few things that we could try to continue improve our model:\n",
    "* Increase the number of model layers (e.g. add more `Conv2D`/`MaxPool2D` layers)\n",
    "* Increase the number of filters in each convolutional layer (e.g. from 10 to 32 or even 64)\n",
    "* Train for longer(more epochs)\n",
    "* Find an ideal learning rate\n",
    "* Get more data (give the model more opportunities to learn)\n",
    "* Use **transfer learning** to leverage what another image model has learnt and adjust it for our own use case\n",
    "\n",
    "> **practice:** Recreate the model on CNN explainer website (same as model_1) and see how it performs on the augmented shuffled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjHlvyzKpRK_",
    "outputId": "a6884f8d-db34-4459-ffa1-9064763247ec"
   },
   "outputs": [],
   "source": [
    "#for practice\n",
    "#create the model\n",
    "model_p = Sequential ([\n",
    "    Conv2D(10,3,activation = \"relu\", input_shape = (224,224,3)),\n",
    "    Conv2D(10,3,activation= \"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10,3,activation = \"relu\"),\n",
    "    Conv2D(10,3,activation = \"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "model_p.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = Adam(),\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "#fit the model\n",
    "history_p = model_p.fit(train_data_augmented_shuffled,\n",
    "                        epochs = 5,\n",
    "                        steps_per_epoch = len(train_data_augmented_shuffled),\n",
    "                        validation_data = test_data,\n",
    "                        validation_steps = len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syAjYVAqqzJl"
   },
   "source": [
    "## making a prediction with our trained model on our own custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inXIuQ2MsGog",
    "outputId": "07e1743c-1c9e-49cf-bf12-76cd116e9466"
   },
   "outputs": [],
   "source": [
    "#Classes  we're working with \n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7gxKenQsK-A",
    "outputId": "43d266c2-75a2-4802-967b-19f55f5b9e25"
   },
   "outputs": [],
   "source": [
    "#view our example \n",
    "import matplotlib.image as mping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\n",
    "steak = mping.imread(\"03-steak.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "7-A80Inms0sk",
    "outputId": "2d9678ed-3d7b-423f-c619-1964ef4803bf"
   },
   "outputs": [],
   "source": [
    "#plot the image\n",
    "plt.imshow(steak)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KuRhFNgwtA7X",
    "outputId": "86fc07f5-e107-4339-d7cf-27a424e62fab"
   },
   "outputs": [],
   "source": [
    "#Check the shape of our image\n",
    "steak.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBDWmgPvu49s"
   },
   "source": [
    "**Note:** when you train a neural network and you want to make a prediction with it on your own custom data, it's important than your custom data (or new data) is preprocessed into the same format as the data your model was trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGaTcPC3uG1j"
   },
   "outputs": [],
   "source": [
    "#Create a function to import an image and resize it to be able to add into our model\n",
    "\n",
    "def load_and_prep_image(filename, img_shape=224):\n",
    " \"\"\"\n",
    " read an image from file name, turns it into a tensor and reshapes it to (img_shape, img_shape, color_channels)\n",
    " \"\"\"\n",
    "\n",
    " #read in the image\n",
    " img = tf.io.read_file(filename)\n",
    " #decode the read file into a tensor\n",
    " img = tf.image.decode_image(img)\n",
    " #resize the image\n",
    " img = tf.image.resize(img, size = [img_shape, img_shape])\n",
    " #rescale the image and get all values between 0 and 1\n",
    " img= img/255.\n",
    " #expand the dimension of the img to include the batch size\n",
    " img = tf.expand_dims(img, axis = 0)\n",
    " return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fj-_v-xGuUSo",
    "outputId": "735572b1-540f-41c6-cf65-62add7493896"
   },
   "outputs": [],
   "source": [
    "#load in an preprocess our custom image\n",
    "steak = load_and_prep_image(\"03-steak.jpeg\")\n",
    "steak.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSH0yos8wi9n",
    "outputId": "20da78f5-ec73-4495-e922-07dd44d2e219"
   },
   "outputs": [],
   "source": [
    "pred = model_7.predict(steak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0xba2BBxvWg"
   },
   "source": [
    "Looks like our custom image is being put through our model, however it currently outputs a prediction probability' wouldnt it be nice if we could visualize the image as well as the model's prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qooLgC18w5G8",
    "outputId": "bd6f36f6-c3eb-48c0-85c8-037f7113506f"
   },
   "outputs": [],
   "source": [
    "#remind ourselves of our class name\n",
    "class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "9KH2WtcvyFrm",
    "outputId": "72f4639b-fab2-4f15-c225-ad8434f87648"
   },
   "outputs": [],
   "source": [
    "#we can index the predicted class by rounding the prediction probability and indexing it on the class_names\n",
    "pred_class = class_names[int(tf.round(pred))]\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdGsUDSWyYVX"
   },
   "outputs": [],
   "source": [
    "def pred_and_plot(model, filename, class_names = class_names):\n",
    "  \"\"\"\n",
    "  Imports an image located at filename, makes a prediction with model and plots the image with the \n",
    "  predicted class as the title.\n",
    "  \"\"\"\n",
    "\n",
    "  #import the target image and preprocessed it\n",
    "  img = load_and_prep_image(filename)\n",
    "\n",
    "  #make a prediction\n",
    "  pred = model.predict(img)\n",
    "\n",
    "  #get the predicted class\n",
    "  pred_class = class_names[int(tf.round(pred))]\n",
    "\n",
    "  #plot the image and predicted class\n",
    "  plt.imshow(tf.squeeze(img))\n",
    "  plt.title(f\"prediction:{pred_class}\")\n",
    "  plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "EBO-_5ZEzPhZ",
    "outputId": "4e97bbe0-8659-4e34-8364-9742f7576958"
   },
   "outputs": [],
   "source": [
    "#test our model on a custom image\n",
    "pred_and_plot(model_7, \"03-steak.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "id": "3ce4td29zlFf",
    "outputId": "65967aae-77db-4810-e5dd-dcc611788859"
   },
   "outputs": [],
   "source": [
    "#get a custom pizza image\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "L6x8UMB000_6",
    "outputId": "6be8fec7-1e2f-4796-963c-473b7dae20c1"
   },
   "outputs": [],
   "source": [
    "pred_and_plot(model_7, \"03-steak.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvSxej_W1Y2j"
   },
   "source": [
    "## multi-class image classification\n",
    "\n",
    "We've been through a bunch of the following steps with a binary classification problem (pizza vs. steak)m now we're going to step things up a notch with 10 classes of food (multi-class classification)\n",
    "\n",
    "1. Become one with the data\n",
    "2. Preprocess the data (get it ready for a model)\n",
    "3. Create a model (start with a baseline)\n",
    "4. Fit the model (overfitting it to make sure it works)\n",
    "5. Evaluate the model\n",
    "6. Adjust different hyperparameters and improve the model (try to beat baseline/reduce overfitting)\n",
    "7. Repeat until satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWTOmJgq6A7c"
   },
   "source": [
    "## 1. import and become one with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H50VTPyT-3Yw",
    "outputId": "5d603b65-c7e3-43fc-f185-9c6dac8273ff"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
    "\n",
    "#unzip our data\n",
    "zip_ref = zipfile.ZipFile(\"10_food_classes_all_data.zip\",\"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2RH84-r_PJF",
    "outputId": "624af0ab-34ae-4012-e48b-75710d5eb4ed"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#walkthough 10 classes of food image data\n",
    "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
    "  print(f\"there are {len(dirnames)} directories and {len(filenames)} images  '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0h2dKC8mALrH",
    "outputId": "8722ad2e-7c30-4664-a8ff-4b627f949b41"
   },
   "outputs": [],
   "source": [
    "!ls -la 10_food_classes_all_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "325QmBTqAV-u"
   },
   "outputs": [],
   "source": [
    "#setup the train and test directories\n",
    "train_dir = \"10_food_classes_all_data/train/\"\n",
    "test_dir = \"10_food_classes_all_data/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcnp6lKgBBgm",
    "outputId": "a67bcf97-94c3-4a49-fde1-796783657a27"
   },
   "outputs": [],
   "source": [
    "#let's get the class names\n",
    "import pathlib\n",
    "import numpy as np\n",
    "data_dir = pathlib.Path(train_dir)\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "xYNvoFizA2gC",
    "outputId": "c5f5fd75-947f-4111-9804-80b9962facf6"
   },
   "outputs": [],
   "source": [
    "#Visualize , visualize, visualize\n",
    "import random \n",
    "img = view_random_image(target_dir = train_dir,\n",
    "                        target_class = random.choice(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "jGslJdYHBntN",
    "outputId": "adc34fc9-f7c5-492f-9fdb-69e601c671f9"
   },
   "outputs": [],
   "source": [
    "random.choice(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0R6QZSqBqNb"
   },
   "source": [
    "### 2. Preprocess the data (prepare it for a model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sUUUHWV_Cvo",
    "outputId": "7e5b8994-ea14-43c0-c18d-b9d4e20b8129"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxifAEkx_E_r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
